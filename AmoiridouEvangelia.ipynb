{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COM3502-4502-6502 Speech Processing - Python Programming Assignment\n",
    "\n",
    "## 1. General Information\n",
    "\n",
    "This programming assignment is worth 55% of the overall course mark.\n",
    "\n",
    "You are free to complete this assignment in your own time. However, feedback, advice and guidance is available during the lab classes and via the discussion board on Blackboard. \n",
    "\n",
    "Note: Via these channels we try to help you as much as possible, but will not debug your code or provide solutions to the assignment itself.\n",
    "\n",
    "Note: It will take some time to complete this assignment, so plan your work accordingly over the coming weeks. Read these instructions carefully.\n",
    "\n",
    "Note: Please be aware that students registered on COM4502 and COM6502 have **additional tasks** to perform. These are marked ‘COM4502-6502 Only’.\n",
    "\n",
    "Note: You should always ensure that your results (e.g. in terms of plots you create) are clear to undrestand and leave no room for mis-interpretation. This can often easily achieved by adding proper $x$- and $y$-axis labels, titles, legends etc. Where results are not clear to interprete, this might result in missed points. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Student Data\n",
    "\n",
    "Student Family Name: <span style=\"font-weight:bold;color:orange\">**Amoiridou**</span>\n",
    "\n",
    "Student Given Name(s): <span style=\"font-weight:bold;color:orange\">**Evangelia**</span>\n",
    "\n",
    "Date of submission: <span style=\"font-weight:bold;color:orange\">**Friday 16th of December 2022**</span>\n",
    "\n",
    "Academic Year 2021/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Copyright\n",
    "\n",
    "This programming assignment is part of the lecture COM[3502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level3/com3502.html \"Open web page for COM3502 module\")-[4502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/level4/com4502.html \"Open web page for COM4502 module\")-[6502](http://www.dcs.shef.ac.uk/intranet/teaching/public/modules/msc/com6502.html \"Open web page for COM4502 module\") Speech Processing at the [University of Sheffield](https://www.sheffield.ac.uk/ \"Open web page of The University of Sheffield\"), Dept. of [Computer Science](https://www.sheffield.ac.uk/dcs \"Open web page of Department of Computer Science\"), University of Sheffield.\n",
    "\n",
    "This notebook is licensed as an assignment to be used during the lecture COM3502-4502-6502 Speech Processing at the University of Sheffield. Any further use is only permitted if agreed with the [module lead](mailto:s.goetze@sheffield.ac.uk).\n",
    "\n",
    "It should be a matter of course that rules of [unfair means](https://www.sheffield.ac.uk/apse/apo/quality/assessment/unfair) apply and the assignment is not to be shared with or made available to other persons besides those participating in the module during the same academic year. This includes publishing on web pages etc. All questions can be asked during the lab classes or using the Blackboard Discussion board.\n",
    "\n",
    "\n",
    "## 1.3 Hand-In Procedure and Deadline\n",
    "\n",
    "Once you have completed the assignment you should submit a `.zip` file (via Blackboard) containing your solution (as a file named `YourName.ipynb`) and possibly other source linked in your Jupyter Notebook. Also the `.zip` filename should be of the form `YourName.zip`. Please make also sure that your name is entered correctly in the section above.\n",
    "\n",
    "Standard departmental penalties apply for [late hand-in](https://sites.google.com/sheffield.ac.uk/comughandbook/general-information/assessment/late-submission) and [plagiarism](https://sites.google.com/sheffield.ac.uk/comughandbook/general-information/assessment/unfair-means).\n",
    "\n",
    "The **deadline** for handing-in this assignment (via Blackboard) is \n",
    "<span style=\"font-weight:bold;color:red\">**Friday 16th December 2022**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task 0:**\n",
    "    \n",
    "Ensure that you data is correctly entered in the section at the top of this sheet and that the filename is in the form `AmoiridouEvangelia.ipynb`. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Libraries\n",
    "\n",
    "You should be familar to the use of the following Python libraries from the lab. You should not need to use additional ones. You are allowed to use additional libraries if necessary for your code. If they need to be installed by `!pip install <libraryname>` or `!conda install <libraryname>`, please indicate this as a comment in your code. You should not make use of libraries that can't be installed by either `!pip install` or `!conda install`. You have to ensure that your Notebook runs \"out of the box\". You can test this on the Computer Lab machines in the Diamond if you are unsure and using your own computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do some necessary and nice-to-have imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt    # plotting\n",
    "#import seaborn as sns; sns.set()  # styling\n",
    "import numpy as np                 # math\n",
    "\n",
    "import soundfile as sf             # to load files\n",
    "from IPython import display as ipd # for sound playback\n",
    "\n",
    "from scipy import signal           # filter designs (if not already imported)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download, load, and analyse audio\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T1:** \n",
    "    \n",
    "* Load a wave file containing speech. You can find a file at <a href=\"https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/speech.wav\"> https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/speech.wav</a> and should be able to download this. You can also use your own WAVE files if you prefer this. If you want to record WAVE files and are using your own computer, the program [Audacity](https://www.audacityteam.org/download/) is one possibility to [record WAVE files](https://manual.audacityteam.org/man/basic_recording_editing_and_exporting.html).\n",
    "    \n",
    "* Visualise the signal in time domain, in the spectral domain (as spectrum) and as a time-frequency representation (spectrogram). Please ensure proper axis labels for all your plot in this assignment.\n",
    "\n",
    "* Playback the signal.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# download file containing speech \n",
    "!curl https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/speech.wav -o speech.wav \n",
    "    \n",
    "import soundfile as sf\n",
    "s_file_name = 'speech.wav'\n",
    "s,fs = sf.read(s_file_name)\n",
    "\n",
    "\n",
    "# visualise signal in time domain\n",
    "plt.figure(figsize=(9,17))\n",
    "t=np.linspace(0,len(s)/fs,len(s)) #create time vector\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(t,s)\n",
    "plt.title('Visualisation of the signal in time domain')\n",
    "plt.xlabel('$t$ in seconds');\n",
    "plt.ylabel('$s(t)$');\n",
    "\n",
    "# visualise signal in spetral domain\n",
    "# calculate the spectum (frequency domain representation)\n",
    "FFT_length = 2**15 # take a power of two which is larger than the signal length\n",
    "f = np.linspace(0, fs/2, num=int(FFT_length/2+1))\n",
    "spectrum = np.abs(np.fft.rfft(s,n=FFT_length))\n",
    "print(spectrum.shape)\n",
    "print(f.shape)\n",
    "\n",
    "# plot the spectrum\n",
    "plt.subplot(3,1,2)   \n",
    "plt.plot(f,spectrum)\n",
    "plt.title('Visualisation of the signal in spectal domain')\n",
    "plt.xlabel('frequency $f$ in Hz')\n",
    "plt.ylabel('$x(f)$')\n",
    "\n",
    "# visualise signal as spectogram\n",
    "plt.subplot(3,1,3)\n",
    "plt.specgram(s, Fs=fs);\n",
    "plt.title('Spectrogram of the signal')\n",
    "plt.xlabel('time $t$')\n",
    "plt.ylabel('frequency $f$')\n",
    "\n",
    "plt.colorbar(label='dB');\n",
    "plt.clim(-150,0)\n",
    "\n",
    "# playback the signal\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(s/10,rate=fs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
    "    \n",
    "**Question Q1:** \n",
    "\n",
    "* Determine the sampling frequency $f_s$ in Hz and the length of the signal in seconds. What is the sampling interval $T_s$ of your signal? What is the highest occuring frequency?\n",
    "    \n",
    "Note: You can either give your answer in form of a code block (e.g. by using the `print()` functions) or as text. For the latter, change the [type of the next cell](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#structure-of-a-notebook-document) from `code` to `markdown` or use the yellow example text below.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here \n",
    "\n",
    "# print sampling frequency of the signal\n",
    "print (\"The sampling frequency of the signal is \"+str(fs)+\" Hz.\")\n",
    "# print length of the signal\n",
    "print (\"The length of the signal is \"+str(len(s)/fs)+\" sec.\")\n",
    "# print samplig interval\n",
    "print (\"The sampling inerval of the signal is \"+str(1/fs)+\" sec.\")\n",
    "# print highest occuring frequency \n",
    "print (\"The highest occuring frequency of the signal is approximately 6500 Hz because it's the highest frequency in which energy can be observed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold;color:orange\">In case you want to answer by written text, we would appreciate if you  colour-code your answers, e.g. like using orange font colour as illustrated in this example. This helps us, not to overlook parts of your answers.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Piece-wise linear filtering in the time domain\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T2:** \n",
    "    \n",
    "* Design a high-pass filter with a cut-off frequency of $\\approx 500$ Hz using a filter design method of your choice. \n",
    "* Design a low-pass filter with a cut-off frequency of $\\approx 500$ Hz.\n",
    "* Design a band-stop filter with a cut-off frequencies of $\\approx 300$ Hz and of $\\approx 1.1$ kHz.\n",
    "* Simulate the effect of a land-line telephone by eliminating all energy below $300$ Hz and above $3,400$ Hz.\n",
    "* Visualise the transfer functions of the filters and the zero-pole plots.\n",
    "* Apply the designed filters, compare filter input and output as a time-frequency visualisation and play back the filtered signal.\n",
    "    \n",
    "Note: Don't forget proper labeling / description of your figures to make clear what is what.\n",
    "    \n",
    "Note: In case you encounter stability problems, rememer that we mentioned in the lecture, that filters can be designed as second-oder-systems (SOS) which the design methods you are familia with can realise.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "\n",
    "# high pass filter tolerance function\n",
    "def plot_tolerance_scheme_hp(Wp=0.25,Ws=0.3,Rp_lin=0.9,Rs_lin=0.1):\n",
    "    dh1x=[Ws,1];  dh1y=[1,1];            # (x,y) coordinates of lines\n",
    "    dh2x=[Wp,1];  dh2y=[Rp_lin,Rp_lin]; \n",
    "    dv2x=[Wp,Wp]; dv2y=[0,Rp_lin];   \n",
    "    sh1x=[0,Ws];  sh1y=[Rs_lin,Rs_lin]; \n",
    "    sh2x=[0,Wp];  sh2y=[0,0]; \n",
    "    svx=[Ws,Ws];  svy=[Rs_lin,1];  \n",
    "   \n",
    "    # plot the actual lines\n",
    "    plt.plot(dh1x,dh1y,'k--',dh2x,dh2y,'k--',dv2x,dv2y,'k--',sh1x,sh1y,'k--',\n",
    "             sh2x,sh2y,'k--',svx,svy,'k--');\n",
    "    plt.xlabel('Frequency $\\Omega/\\pi$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design high-pass filter, cut-off frequency 500Hz using butterworth method\n",
    "# assuming 10% tolerance, fs=8000Hz ripples=10%\n",
    "\n",
    "from scipy import signal as sig         # filter designs\n",
    "\n",
    "wp1=0.025;                  # passband edge frequency \n",
    "ws1=0.020;                  # stopband edge frequency \n",
    "Rp_lin1=0.8;                # allowed ripples in the pass band area\n",
    "Rs_lin1=0.2;                # allowed ripples in the stop band area\n",
    "\n",
    "Rp1=-20*np.log10(Rp_lin1);  # max passband ripple in dB\n",
    "Rs1=-20*np.log10(Rs_lin1);  # min stopband attenuation in dB\n",
    "plot_tolerance_scheme_hp(wp1,ws1,Rp_lin1,Rs_lin1)\n",
    "\n",
    "# get lowest filter order N to fullfill requirements above\n",
    "N1, Wn1 = sig.buttord(wp1, ws1, Rp1, Rs1) \n",
    "b1, a1 = sig.butter(N1, Wn1, 'high')\n",
    "\n",
    "print('The minimum possible filter order to fulfil the tolerance scheme is '+str(N1)+'.')\n",
    "print('The cut-off frequency which will be {:.2f}.'.format(Wn1))  \n",
    "\n",
    "b1, a1 = signal.butter(N1, Wn1, 'highpass')\n",
    "f1,h1 = signal.freqz(b1,a1)\n",
    "omega1 = np.linspace(0,1,len(f1))\n",
    "\n",
    "plot_tolerance_scheme_hp(wp1,ws1,Rp_lin1,Rs_lin1)\n",
    "plt.plot([Wn1,Wn1],[0,1],color='red',ls=':',label='cutoff frequency')\n",
    "plt.plot(omega1,np.abs(h1), lw=2, label='Butterworth high-pass')\n",
    "\n",
    "plt.title('Butterworth h-pass filter of order ' + str(N1))\n",
    "plt.ylabel('Amplitude $|h(e^{j \\Omega})|$')\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "# visualise transfer functions and zero-pole pots of the filters\n",
    "\n",
    "# plot frequency response of high-pass filter, cut-off frequency 500Hz\n",
    "fig = plt.figure(figsize=(8,4)) # create a figure of size 8 x 4 inches\n",
    "h1 = np.abs(np.fft.fft(b1,1024))/np.abs(np.fft.fft(a1,1024));\n",
    "h1 = h1[0:513] # only show first half (positive frequencies)\n",
    "omega = np.linspace(0,1,513)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(omega, abs(h1), lw=2)\n",
    "plt.title('Butterworth high-pass filter \\n f>500Hz')\n",
    "plt.ylabel('Amplitude $|h(e^{j \\Omega})|$');\n",
    "\n",
    "def zplane(z, p, title='Poles and Zeros'):\n",
    "    \"Plots zeros and poles in the complex z-plane\"\n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.plot(np.real(z), np.imag(z), 'bo', fillstyle='none', ms=10)\n",
    "    ax.plot(np.real(p), np.imag(p), 'rx', fillstyle='none', ms=10)\n",
    "    unit_circle = plt.Circle((0, 0), radius=1, fill=False,\n",
    "                             color='black', ls='--', alpha=0.9)\n",
    "    ax.add_patch(unit_circle)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Re{$z$}')\n",
    "    plt.ylabel('Im{$z$}')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "# plot zero-pole plot of high-pass filter, cut-off frequency 500Hz    \n",
    "plt.subplot(1,2,2)\n",
    "zplane(-1, np.roots(a1))\n",
    "plt.text(-0.95,0.1,'('+str(N1)+')');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low pass filter tolerance function\n",
    "\n",
    "def plot_tolerance_scheme(Wp=0.020,Ws=0.025,Rp_lin=0.8,Rs_lin=0.2):\n",
    "    dh1x=[0,Ws];  dh1y=[1,1];            # (x,y) coordinates of lines\n",
    "    dh2x=[0,Wp];  dh2y=[Rp_lin,Rp_lin]; \n",
    "    dv2x=[Wp,Wp]; dv2y=[0,Rp_lin];   \n",
    "    sh1x=[Ws,1];  sh1y=[Rs_lin,Rs_lin]; \n",
    "    sh2x=[Wp,1];  sh2y=[0,0]; \n",
    "    svx=[Ws,Ws];  svy=[Rs_lin,1];  \n",
    "    # plot the actual lines\n",
    "    plt.plot(dh1x,dh1y,'k--',dh2x,dh2y,'k--',dv2x,dv2y,'k--',sh1x,sh1y,'k--',\n",
    "             sh2x,sh2y,'k--',svx,svy,'k--');\n",
    "    plt.xlabel('Frequency $\\Omega/\\pi$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design low-pass filter, cut-off frequency 500Hz using butterworth method\n",
    "# assuming 10% tolerance, fs=8000Hz ripples=10%\n",
    "\n",
    "wp2=0.020;                  # passband edge frequency \n",
    "ws2=0.025;                  # stopband edge frequency \n",
    "Rp_lin2=0.8;                # allowed ripples in the pass band area\n",
    "Rs_lin2=0.2;                # allowed ripples in the stop band area\n",
    "\n",
    "Rp2=-20*np.log10(Rp_lin2);  # max passband ripple in dB\n",
    "Rs2=-20*np.log10(Rs_lin2);  # min stopband attenuation in dB\n",
    "plot_tolerance_scheme_hp(wp2,ws2,Rp_lin2,Rs_lin2)\n",
    "\n",
    "# get lowest filter order N to fullfill requirements above\n",
    "N2, Wn2 = sig.buttord(wp2, ws2, Rp2, Rs2) \n",
    "b2, a2 = sig.butter(N2, Wn2, 'low')\n",
    "\n",
    "print('The minimum possible filter order to fulfil the tolerance scheme is '+str(N2)+'.')\n",
    "print('The cut-off frequency which will be {:.2f}.'.format(Wn2)) # format number - two digits after decimal pt.\n",
    "\n",
    "\n",
    "# visualise transfer functions and zero-pole pots of the filters\n",
    "\n",
    "# plot frequency response of low-pass filter, cut-off frequency 500Hz\n",
    "fig=plt.figure(figsize=(8,4))         # create a figure of size 8 x 4 inches\n",
    "h2=np.abs(np.fft.fft(b2,1024))/np.abs(np.fft.fft(a2,1024));\n",
    "h2=h2[0:513]                          # only show first half (positive frequencies)\n",
    "omega=np.linspace(0,1,513)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(omega, abs(h2), lw=2)\n",
    "plt.title('Butterworth low-pass filter \\n f<500Hz')\n",
    "plt.ylabel('Amplitude $|h(e^{j \\Omega})|$');\n",
    "\n",
    "def zplane(z, p, title='Poles and Zeros'):\n",
    "    \"Plots zeros and poles in the complex z-plane\"\n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.plot(np.real(z), np.imag(z), 'bo', fillstyle='none', ms=10)\n",
    "    ax.plot(np.real(p), np.imag(p), 'rx', fillstyle='none', ms=10)\n",
    "    unit_circle = plt.Circle((0, 0), radius=1, fill=False,\n",
    "                             color='black', ls='--', alpha=0.9)\n",
    "    ax.add_patch(unit_circle)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Re{$z$}')\n",
    "    plt.ylabel('Im{$z$}')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "# plot zero-pole plot of lowh-pass filter, cut-off frequency 500Hz    \n",
    "plt.subplot(1,2,2)\n",
    "zplane(-1, np.roots(a2))\n",
    "plt.text(-0.95,0.1,'('+str(N2)+')');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design band-stop filter, cut-off frequency 300Hz and 1100HZ using butterworth method\n",
    "\n",
    "wp3 = [0.016, 0.04]       # pass-band frequency limits (normalised)\n",
    "ws3 = [0.01, 0.06]        # stop-band frequency limits (normalised)\n",
    "Rp3 = 1                   # allowed ripples in the pass band area (1 dB)\n",
    "Rs3 = 20                  # allowed ripples in the stop band area (20dB)\n",
    "\n",
    "# determine necessary filter order as well as cut-off frequencies\n",
    "N3, Wn3 = signal.buttord(wp3, ws3, Rp3, Rs3)\n",
    "b3, a3 = sig.butter(N3, Wn3, 'bandstop')\n",
    "f3,h3 = sig.freqz(b3,a3)\n",
    "omega3 = np.linspace(0,1,len(f3))\n",
    "plt.plot(omega3, np.abs(h3))\n",
    "\n",
    "print('The minimum possible filter order to fulfil the tolerance scheme is '+str(N3)+'.')\n",
    "print('The 1st cut-off frequency which will be {:.2f}.'.format(Wn3[0])) \n",
    "print('The 2nd cut-off frequency which will be {:.2f}.'.format(Wn3[1])) \n",
    "\n",
    "# plot frequency response of band-stop filter, cut-off frequencies 300Hz and 1100Hz\n",
    "f3,h3 = sig.freqz(b3,a3)\n",
    "omega3 = np.linspace(0,1,len(f3))\n",
    "fig = plt.figure(figsize=(8,4))      # create a figure of size 8 x 4 inches\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(omega3, np.abs(h3))\n",
    "plt.title('Butterworth band-stop filter \\n 300Hz>f and  f>1100Hz')\n",
    "plt.ylabel('Amplitude $|h(e^{j \\Omega})|$')\n",
    "plt.xlabel('Frequency $\\Omega / \\pi$')\n",
    "plt.grid(True,which='both', axis='both')\n",
    "\n",
    "# plot zero-pole plot of band-stop filter, cut-off frequencies 300Hz and 1100Hz\n",
    "plt.subplot(1,2,2)\n",
    "zplane(-1, np.roots(a3))\n",
    "plt.text(-0.95,0.1,'('+str(N3)+')');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#design band-pass filter, cut-off frequency 300Hz and 3400HZ using butterworth method\n",
    "wp4 = [0.018,0.10]       # pass-band frequency limits (normalised)\n",
    "ws4 = [0.008,0.2]       # stop-band frequency limits (normalised)\n",
    "Rp4 = 1                  # allowed ripples in the pass band area (1 dB)\n",
    "Rs4 = 20                 # allowed ripples in the stop band area (20dB)\n",
    "Rp_lin4 = 10**(-Rs4/20); # transforming dB back to linear        \n",
    "Rs_lin4 = 10**(-Rs4/20)         \n",
    "\n",
    "# determine necessary filter order as well as cut-off frequencies\n",
    "N4, Wn4 = signal.buttord(wp4, ws4, Rp4, Rs4)\n",
    "b4, a4 = sig.butter(N4, Wn4, 'bandpass')\n",
    "f4,h4 = sig.freqz(b4,a4)\n",
    "omega4 = np.linspace(0,1,len(f4))\n",
    "plt.plot(omega4, np.abs(h4))\n",
    "\n",
    "print('The minimum possible filter order to fulfil the tolerance scheme is '+str(N4)+'.')\n",
    "print('The 1st cut-off frequency which will be {:.2f}.'.format(Wn4[0])) \n",
    "print('The 2nd cut-off frequency which will be {:.2f}.'.format(Wn4[1])) \n",
    "\n",
    "# plot frequency response of band-stop filter, cut-off frequencies 300Hz and 3400Hz\n",
    "f4,h4 = sig.freqz(b4,a4)\n",
    "omega4 = np.linspace(0,1,len(f4))\n",
    "fig = plt.figure(figsize=(8,4)) \n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(omega4, np.abs(h4))\n",
    "plt.title('Butterworth band-pass filter \\n 300Hz< f <3400Hz')\n",
    "plt.ylabel('Amplitude $|h(e^{j \\Omega})|$')\n",
    "plt.xlabel('Frequency $\\Omega / \\pi$')\n",
    "plt.grid(True,which='both', axis='both')\n",
    "\n",
    "# plot zero-pole plot of band-stop filter, cut-off frequencies 300Hz and 3400Hz\n",
    "plt.subplot(1,2,2)\n",
    "zplane(-1, np.roots(a4))\n",
    "plt.text(-0.95,0.1,'('+str(N4)+')');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_filtered1 = signal.filtfilt(b1, a1, s)   #high pass\n",
    "s_filtered2 = signal.filtfilt(b2, a2, s)   #low pass\n",
    "s_filtered3 = signal.filtfilt(b3, a3, s)   #bandstop\n",
    "s_filtered4 = signal.filtfilt(b4, a4, s)   #bandpass\n",
    "\n",
    "ipd.Audio(s_filtered4, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise as spectrograms\n",
    "fig=plt.figure(figsize=(15,6))    # create a figure of size 15 x 6 inches\n",
    "\n",
    "plt.subplot(1,5,1)\n",
    "plt.specgram(s, Fs=fs)\n",
    "plt.title('spectrogram of signal \\n before filtering')\n",
    "plt.xlabel('time $t$')\n",
    "plt.ylabel('frequency $f$')\n",
    "plt.grid(False)                   # no grid (in case you used seaborn)\n",
    "\n",
    "plt.colorbar(label='dB');\n",
    "plt.clim(-180,-30)                # select the 'color'/amplitude range (in dB)\n",
    "\n",
    "plt.subplot(1,5,2)\n",
    "plt.specgram(s_filtered1, Fs=fs)\n",
    "plt.title('spectrogram of filtered signal \\n high-pass f>500')\n",
    "plt.xlabel('time $t$')\n",
    "plt.ylabel('frequency $f$')\n",
    "plt.grid(False)                   # no grid (in case you used seaborn)\n",
    "\n",
    "plt.colorbar(label='dB');\n",
    "plt.clim(-180,-30)\n",
    "\n",
    "plt.subplot(1,5,3)\n",
    "plt.specgram(s_filtered2, Fs=fs)\n",
    "plt.title('spectrogram of filtered signal \\n low-pass f<500')\n",
    "plt.xlabel('time $t$')\n",
    "plt.ylabel('frequency $f$')\n",
    "plt.grid(False)                   # no grid (in case you used seaborn)\n",
    "\n",
    "plt.colorbar(label='dB');\n",
    "plt.clim(-180,-30)\n",
    "plt.subplot(1,5,4)\n",
    "plt.specgram(s_filtered3, Fs=fs)\n",
    "plt.title('spectrogram of filtered signal \\n 300Hz>f and f>1100Hz')\n",
    "plt.xlabel('time $t$')\n",
    "plt.ylabel('frequency $f$')\n",
    "plt.grid(False)                   # no grid (in case you used seaborn)\n",
    "\n",
    "plt.colorbar(label='dB');\n",
    "plt.clim(-180,-30)\n",
    "\n",
    "plt.subplot(1,5,5)\n",
    "plt.specgram(s_filtered4, Fs=fs)\n",
    "plt.title('spectrogram of filtered signal \\n 300Hz< f <3400Hz')\n",
    "plt.xlabel('time $t$')\n",
    "plt.ylabel('frequency $f$')\n",
    "plt.grid(False)                    # no grid (in case you used seaborn)\n",
    "\n",
    "plt.colorbar(label='dB');\n",
    "plt.clim(-180,-30)\n",
    "\n",
    "plt.tight_layout()                 # to see all axis descriptions\n",
    "\n",
    "#play back the filtered signal\n",
    "import IPython.display as ipd\n",
    "print(\"filtered signal 1, high-pass filter f>500Hz\")\n",
    "ipd.display(ipd.Audio(s_filtered1/10,rate=fs))\n",
    "print(\"filtered signal 2, low-pass filter f<500Hz\")\n",
    "ipd.display(ipd.Audio(s_filtered2/10,rate=fs))\n",
    "print(\"filtered signal 3, band-stop filter 300Hz>f and  f>1100Hz\")\n",
    "ipd.display(ipd.Audio(s_filtered3/10,rate=fs))\n",
    "print(\"filters signal 4, band-pass filter 300Hz< f <3400Hz\")\n",
    "ipd.display(ipd.Audio(s_filtered4/10,rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
    "    \n",
    "**Question Q2:** \n",
    "\n",
    "* Explain the behaviour of the designed band-stop filter, i.e. describe (briefly) what you can see in the generated plots. If you didn't generate plots you can explain what you would expect to see.\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Question Q2:**\n",
    "\n",
    "<span style=\"font-weight:bold;color:orange\">\n",
    "    The band-stop filter plot shows that the signal that is being processed starts from level 1 up to 300Hz, then goes to 0 unti it reaches 1100Hz and finally it goes up to 1 until it reaches infinity. That means that the frequencies below 300Hz and above 1100Hz are multiplied by one and the frequencies in the middle, they are multiplied by 0.\n",
    "    If we look at the spectogram, we can see that there are shades of light green and blue. At the bottom of the spectogram we can spot a blue horizontal line that shows that there is no signal in that frequency. This line is equal to the frequency between 300Hz and 1100Hz.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
    "    \n",
    "**Question Q3:**\n",
    "    \n",
    "* Which sounds are most affected when the low-pass cut-off frequency is set to around $500$\n",
    "Hz - vowels or consonants - and why?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Question Q3:**\n",
    "\n",
    "<span style=\"font-weight:bold;color:orange\">\n",
    "    As a general observation, vowels tend to be lower in frequency comparing to consonants. Looking at the low-pass filter we notice that the vowels keep almost the same quality of sound while the consonants are being filtered and their quality deteriorates. As a result the consonants end up sounding less clear comparing to the vowels. On the other hand, in the case of the high-pass filter, we end up with the exact opposite effect; The consonants sound clearer while it's getting more difficult to distinguish the sound of the vowels.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Audio Effects\n",
    "\n",
    "### 4.1 Low Frequency Oscillator\n",
    "\n",
    "Many ‘Voice effects (FX)’ are achieved by modifying some characteristic of the speech using a low frequency oscillator or *LFO*. LFOs typically have two controls: speed (which is specified by the frequency in Hertz) and depth (which specifies the magnitude of the effect). The following tasks will require several LFOs, so it makes sense to implement one in the following.\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T3:**\n",
    "    \n",
    "* Implement a Low Frequency Oscillator as a function `lfo()` as described below. Visualise that your function works be generating a sine and a square wave of frequency $5$ Hz and length $2$ seconds with different depths.\n",
    "    \n",
    "Note: There will be an extra point in the marking if you **do not** use the `scipy` library to solve this task.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSquare(f0=1, length = 6, fs=44100, order=10):\n",
    "    t_square=np.arange(0,length,1/fs)        # time vector\n",
    "    sum = np.zeros(len(t_square))            # pre-allocate variable with zeros \n",
    "    for ii in range(1, order+1, 2):\n",
    "        sum += np.sin(2*np.pi*ii*f0*t_square)/ii\n",
    "        #print(str(ii)+': adding sin(2 $\\pi$ '+str(ii*f0)+' Hz t)')\n",
    "    return 4/np.pi*sum, t_square\n",
    "\n",
    "f0=1                                         # desired frequency in Hz\n",
    "rec,t_square = generateSquare(f0,order=100)\n",
    "plt.plot(t_square,rec,label='square Fourier');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal as sig         # filter designs\n",
    "t_t3 = np.linspace(0, 2, num = 88200)\n",
    "\n",
    "def lfo1(speed_hz, depth, num_samples, fs=44100, square_curve=False):\n",
    "    '''\n",
    "    Low-frequency oscillator\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    speed_hz : float\n",
    "       frequency of generated signal in Hertz\n",
    "    depth : float\n",
    "        magnitude of the effect\n",
    "    num_samples : int\n",
    "        length of the signal in samples\n",
    "    fs : float, optional \n",
    "        sampling frequency in Hz, default 44100\n",
    "    square_curve : boolean, optional (default: False)\n",
    "        generate square wave if true, generate sine wave if false\n",
    "\n",
    "    Example use:\n",
    "    -------\n",
    "        sig_square = lfo(speed_hz=5, depth=0.7, num_samples=88200, fs=44100, square_curve=True)\n",
    "    '''\n",
    "    \n",
    "    # Your code here \n",
    "    if square_curve==True:\n",
    "        r,s1= generateSquare(speed_hz,2,fs,10)\n",
    "        r=r*depth\n",
    "    else:\n",
    "        s1 = depth * np.sin(2*np.pi*speed_hz*t_t3) \n",
    "        r=0\n",
    "    return (r,s1,sig)  \n",
    "r, t_square,whatever = lfo1(speed_hz=5, depth=2, num_samples=88200, fs=44100, square_curve=True)\n",
    "r1,s1,whatever= lfo1(speed_hz=5, depth=2, num_samples=88200, fs=44100, square_curve=False)\n",
    "fig=plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t_t3,r )\n",
    "plt.title('Visualisation of the square filter ')\n",
    "plt.xlabel('$t$ in seconds');\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t_t3,s1)\n",
    "plt.title('Visualisation of the sine filter ')\n",
    "plt.xlabel('$t$ in seconds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal as sig         # filter designs\n",
    "\n",
    "t = np.linspace(0, 2, num = 88200)\n",
    "\n",
    "def lfo(speed_hz, depth, num_samples, fs=44100, square_curve=False):\n",
    "    '''\n",
    "    Low-frequency oscillator\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    speed_hz : float\n",
    "       frequency of generated signal in Hertz\n",
    "    depth : float\n",
    "        magnitude of the effect\n",
    "    num_samples : int\n",
    "        length of the signal in samples\n",
    "    fs : float, optional \n",
    "        sampling frequency in Hz, default 44100\n",
    "    square_curve : boolean, optional (default: False\n",
    "        generate square wave if true, generate sine wave if false\n",
    "\n",
    "    Example use:\n",
    "    -------\n",
    "        sig_square = lfo(speed_hz=5, depth=0.7, num_samples=88200, fs=44100, square_curve=True)\n",
    "    '''\n",
    "    if square_curve==True:\n",
    "        signal1 = depth * sig.square(2 * np.pi * speed_hz * t)\n",
    "    else:\n",
    "        signal1 = depth * np.sin(2*np.pi*speed_hz*t) \n",
    "    return (signal1)  \n",
    "\n",
    "sig_square = lfo(speed_hz=5, depth=0.7, num_samples=88200, fs=44100, square_curve=True)\n",
    "sig_sin = lfo(speed_hz=5, depth=0.7, num_samples=88200, fs=44100, square_curve=False)\n",
    "\n",
    "fig=plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t,sig_square)\n",
    "plt.title('Visualisation of the square filter ')\n",
    "plt.xlabel('$t$ in seconds');\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t,sig_sin)\n",
    "plt.title('Visualisation of the sine filter ')\n",
    "plt.xlabel('$t$ in seconds');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although your function outputs audio, you are unlikely to be able to hear it as the frequency is so low. However, you can check that it is functioning correctly by combining is with other audio signals as we will do in the following.\n",
    "\n",
    "### 4.2 Amplitude Modulation - Tremolo\n",
    "\n",
    "*Tremolo* is one of the most basic voice manipulations that makes use of an LFO. In this effect, the amplitude of a speech signal is [modulated](https://en.wikipedia.org/wiki/Amplitude_modulation), i.e. the speech waveform is multiplied by a variable gain that ranges between $0$ and $1$. \n",
    "\n",
    "Your LFO outputs an audio signal between `-depth` and `+depth`. So, in order to modulate the amplitude of the speech correctly, the output of the LFO has to be scaled appropriately to range between $0$ and $1$.\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T4:**\n",
    "    \n",
    "* Implement  a function `tremolo()` using your function `lfo()` and modulate the amplitude of the speech signal. \n",
    "* Experiment with different settings for `speed` and `depth`. In particular, note that a square wave with speed between $3$ and $4$ Hz (and depth = $1$) has a very destructive effect on the intelligibility of the output. This is because $3-4$ Hz corresponds to the typical syllabic rate of speech.\n",
    "* Proof that the effect works by a proper visualisation of the filtered speech signal and describe what can be observed and perceived.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tremolo(signal, fs, speed_hz, depth, square_curve=False):\n",
    "    t=np.linspace(0,len(signal)/fs,len(signal))\n",
    "    signal2 = lfo(speed_hz=speed_hz, depth=depth, num_samples=len(signal), fs=fs, square_curve=square_curve)\n",
    "    scaled_signal2 = 0.5 + (1/(2*depth)) * signal2 #scale signal so it ranges ron 0 to 1\n",
    "    modulated_signal = np.multiply(scaled_signal2,signal)\n",
    "    return (modulated_signal)\n",
    "t=np.linspace(0,len(s)/fs,len(s))  \n",
    "\n",
    "\n",
    "#experiment with different settings for speed\n",
    "#the depth of the LFO is irrelevant as the signal get scaled to range from 0 to 1\n",
    "print(\"tremolo effect, square LFO, speed = 300Hz\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=200, depth=1, square_curve=True)/10,rate=fs))\n",
    "print(\"tremolo effect, sine LFO, speed = 300Hz\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=200, depth=1, square_curve=False)/10,rate=fs))\n",
    "print(\"tremolo effect, square LFO, speed = 3.5Hz\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=3.5, depth=1, square_curve=True)/10,rate=fs))\n",
    "print(\"tremolo effect, sine LFO, speed = 3.5Hz\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=3.5, depth=1, square_curve=False)/10,rate=fs))\n",
    "\n",
    "# Proof that the effect works by a proper visualisation of the filtered speech signal\n",
    "\n",
    "start_sample = int(7*fs);                   # start at 7 sec\n",
    "no_of_samples = 10000;                          \n",
    "end_sample   = start_sample + no_of_samples; \n",
    "sample_vec = np.linspace(start_sample, end_sample, no_of_samples)\n",
    "\n",
    "fig=plt.figure(figsize=(8,7.5))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "x=s[start_sample:end_sample];\n",
    "t_sample=t[start_sample:end_sample];\n",
    "\n",
    "plt.plot(t_sample,x,)\n",
    "plt.xlabel('$t$ in seconds')\n",
    "plt.title('original signal - 7.00sec to 7.25sec')\n",
    "\n",
    "\n",
    "s1=tremolo(signal=s, fs=fs, speed_hz=20, depth=1, square_curve=False)\n",
    "x1=s1[start_sample:end_sample];\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(t_sample,x1,)\n",
    "plt.xlabel('$t$ in seconds')\n",
    "plt.title('tremolo effect, sine LFO, speed = 20Hz - 7.00sec to 7.25sec')\n",
    "plt.tight_layout() \n",
    "\n",
    "s2=tremolo(signal=s, fs=fs, speed_hz=20, depth=1, square_curve=True)\n",
    "x2=s2[start_sample:end_sample];\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(t_sample,x2,)\n",
    "plt.xlabel('$t$ in seconds')\n",
    "plt.title('tremolo effect, square LFO, speed = 20Hz - 7.00sec to 7.25sec')\n",
    "\n",
    "plt.tight_layout() \n",
    "\n",
    "print('To demonstrate that the the tremolo effect function works the graphs show the original signal as well as two modulated signals in time domain for a time window between 7.00 sec and 7.25sec.')\n",
    "print( )\n",
    "print('The first modulated signal results from a sine wave LFO of 20Hz speed. The amplitude of the modulated signal follows a sinusoidal envelope with a period equal to 1/20Hz = 0.05sec.')\n",
    "print( )\n",
    "print('The second modulated signal results from a square wave LFO of 20Hz speed. The  modulated signal consists of plateaus of zero value lasting 0.025sec followed by regions where it is equal to the original signal lasting 0.025sec. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Ring Modulation\n",
    "\n",
    "Another basic effect is to multiply the speech signal by the output of an LFO. This is known as ‘ring modulation’.\n",
    "\n",
    "Note: In the BBC TV series [Dr. Who](https://en.wikipedia.org/wiki/Doctor_Who), the voices of the alien [Daleks](https://en.wikipedia.org/wiki/Dalek) are generated by a ring modulator with an LFO set to around 30 Hz. The voice actors also spoke using a stilted monotonic intonation in order to enhance the effect. You can try this yourself by recording your own voice and applying the effect.\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T5 (Ring Modulation):**\n",
    "    \n",
    "* Implement  a function `ring_modulation()` using your function `lfo()` and modulate the amplitude of the speech signal by multiplying with the LFO signal. \n",
    "* Experiment with different settings for `speed` and `depth`. Note how the timbre of the resulting sound is subtly different from *tremolo*.\n",
    "* Proof that the effect works by a proper visualisation of the filtered speech signal and describe what can be observed and perceived.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ring_modulation(signal, fs, speed_hz, depth, square_curve=False):\n",
    "    t=np.linspace(0,len(signal)/fs,len(signal))\n",
    "    signal2 = lfo(speed_hz=speed_hz, depth=depth, num_samples=len(signal), fs=fs, square_curve=square_curve)\n",
    "    modulated_signal = np.multiply(signal2,signal)\n",
    "    return (modulated_signal)\n",
    "t=np.linspace(0,len(s)/fs,len(s))  \n",
    "\n",
    "\n",
    "#experiment with different settings for speed and depth\n",
    "\n",
    "print(\"tremolo effect, square LFO, speed = 300Hz, depth=0.7\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=200, depth=0.7, square_curve=True)/10,rate=fs))\n",
    "print(\"tremolo effect, sine LFO, speed = 300Hz, depth=0.7\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=200, depth=0.7, square_curve=False)/10,rate=fs))\n",
    "print(\"tremolo effect, square LFO, speed = 3.5Hz , depth=0.2\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=3.5, depth=0.2, square_curve=True)/10,rate=fs))\n",
    "print(\"tremolo effect, sine LFO, speed = 3.5Hz, depth=0.2\")\n",
    "ipd.display(ipd.Audio(tremolo(signal=s, fs=fs, speed_hz=3.5, depth=0.2, square_curve=False)/10,rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to show an example of the Ring Modulation effect\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "import numpy as np               # math\n",
    "\n",
    "#read soundfile that is already downloaded\n",
    "import soundfile as sf\n",
    "s_file_name = 'speech.wav'\n",
    "s,fs = sf.read(s_file_name)\n",
    "\n",
    "from scipy import signal as sig         # filter designs\n",
    "import scipy.signal as sig\n",
    "\n",
    "def nextpow2(n):\n",
    "    return int(np.ceil(np.log2(np.abs(n))))\n",
    "\n",
    "def frequency_shift(signal, fs, shift_amount):\n",
    "    N_orig = len(signal)\n",
    "    N_padded = 2 ** nextpow2(N_orig)\n",
    "    t = np.arange(0, N_padded)\n",
    "    return (sig.hilbert(np.hstack((signal, np.zeros(N_padded - N_orig, signal.dtype))))* np.exp(2j * np.pi * shift_amount * t / fs))[:N_orig].real\n",
    "\n",
    "\n",
    "signal_shifted = frequency_shift(s, fs, 10000)\n",
    "                   \n",
    "\n",
    "# calculate the spectum (frequency domain representation)\n",
    "FFT_length = 2**15 # take a power of two which is larger than the signal length\n",
    "f = np.linspace(0, fs/2, num=int(FFT_length/2+1))\n",
    "spectrum = np.abs(np.fft.rfft(s,n=FFT_length))\n",
    "# plot the spectrum\n",
    "plt.subplot(2,1,1)   \n",
    "plt.plot(f,spectrum)\n",
    "plt.title('Visualisation of the signal in spectral domain')\n",
    "plt.xlabel('frequency $f$ in Hz')\n",
    "plt.ylabel('$x(f)$')\n",
    "\n",
    "spectrum1 = np.abs(np.fft.rfft(signal_shifted,n=FFT_length))\n",
    "plt.subplot(2,1,2)   \n",
    "plt.plot(f,spectrum1)\n",
    "plt.title('Visualisation of the signal in spectral domain')\n",
    "plt.xlabel('frequency $f$ in Hz')\n",
    "plt.ylabel('$x(f)$')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Frequency Shifting\n",
    "\n",
    "Many Vocal FX are the result of altering the frequencies present, e.g. changing the pitch of a voice. There are many algorithms for frequency shifting. You have already implemented an approximate solution with your ring modulator.\n",
    "\n",
    "For simplicity, the following function will be givem implementing frequency shifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code in this cell is taken and slightly adapted from:\n",
    "# https://gist.github.com/lebedov/4428122\n",
    "\n",
    "import scipy.signal as sig\n",
    "\n",
    "def nextpow2(n):\n",
    "    '''Return the first integer N such that 2**N >= abs(n)'''\n",
    "    return int(np.ceil(np.log2(np.abs(n))))\n",
    "\n",
    "def frequency_shift(signal, fs, shift_amount):\n",
    "    '''\n",
    "    Shift the specified signal by the specified frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : float\n",
    "       input signal to which the effect should be applied\n",
    "    fs : int\n",
    "        sampling frequency in Hz\n",
    "    shift_amount : float\n",
    "       amount of frequency shift (in Hz)\n",
    "   \n",
    "    Return\n",
    "    ----------\n",
    "    signal after application of the frequancy shifting effect\n",
    "    \n",
    "    Example use:\n",
    "    -------\n",
    "        signal_frequency_shifted = frequency_shift(audio_in, fs, 100)\n",
    "    '''\n",
    "\n",
    "    # Pad the signal with zeros to prevent the FFT invoked by the transform from\n",
    "    # slowing down the computation:\n",
    "    N_orig = len(signal)\n",
    "    N_padded = 2 ** nextpow2(N_orig)\n",
    "    t = np.arange(0, N_padded)\n",
    "    return (\n",
    "        sig.hilbert(\n",
    "            np.hstack((signal, np.zeros(N_padded - N_orig, signal.dtype)))\n",
    "        )\n",
    "        * np.exp(2j * np.pi * shift_amount * t / fs)\n",
    "    )[:N_orig].real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T6 (Frequency Shifting):**\n",
    "    \n",
    "* Visualise the effect of the frequency shift effect using an appropriate spectral representation.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def nextpow2(n):\n",
    "    return int(np.ceil(np.log2(np.abs(n))))\n",
    "\n",
    "def frequency_shift(signal, fs, shift_amount):\n",
    "    N_orig = len(signal)\n",
    "    N_padded = 2 ** nextpow2(N_orig)\n",
    "    t = np.arange(0, N_padded)\n",
    "    return (sig.hilbert(np.hstack((signal, np.zeros(N_padded - N_orig, signal.dtype))))* np.exp(2j * np.pi * shift_amount * t / fs))[:N_orig].real\n",
    "\n",
    "signal_shifted = frequency_shift(s, fs,100)\n",
    "# calculate the spectum (frequency domain representation)\n",
    "FFT_length = 2**15 # take a power of two which is larger than the signal length\n",
    "f = np.linspace(0, fs/2, num=int(FFT_length/2+1))\n",
    "spectrum = np.abs(np.fft.rfft(s,n=FFT_length))\n",
    "spectrum_shifted = np.abs(np.fft.rfft(signal_shifted,n=FFT_length))\n",
    "\n",
    "# plot the spectra\n",
    "f_sample=f[0:800]\n",
    "spectrum_sample=spectrum[0:800]\n",
    "spectrum_shifted_sample=spectrum_shifted[0:800]\n",
    "plt.plot(f_sample,spectrum_sample,label='original signal')\n",
    "plt.plot(f_sample,spectrum_shifted_sample,'r',label='100Hz shift')\n",
    "plt.title('Visualisation of the signal in spectal domain')\n",
    "plt.xlabel('frequency $f$ in Hz')\n",
    "plt.ylabel('$x(f)$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(s/10,rate=fs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(signal_shifted/10,rate=fs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
    "    \n",
    "**Question Q4:**\n",
    "\n",
    "* COM3502-4502-6502: Why can the voice be shifted up in frequency much further than\n",
    "it can be shifted down in frequency before it becomes severely distorted? Hint: Calculate a spectrum plot if the answer is not immediately clear to you.\n",
    "* COM4502-6502 ONLY: Your frequency shifter changes all the frequencies present in an input signal. How might it be possible to change the pitch of a voice without altering the formant frequencies?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Question Q4:**\n",
    "\n",
    "<span style=\"font-weight:bold;color:orange\">\n",
    "    First part of the question: The lower frequencies occupy the biggest part of the voice energy. If the frequencies that occupy the voice are being shifted from high to low, then the lowest frequency is being removed. That means that the lower the frequency when shifting the signal, the more the voice will be distorted. However, going up in frequency then the voice is not that severely affected as the frequencies can go higher without removing the lower frequencies, which are the ones that give more power, energy and value to the voice. \n",
    "    Second part of the question: This could be possible by modifying the formant frequancies of the signal in order to apply another energy distribution on the same frequencies by modulating (apply tremolo effect for example) or filtering the signal.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Harmony Effect\n",
    "\n",
    "A classic ‘robotic’ voice can be achieved by simply adding frequency-shifted speech back to the unprocessed original. This effect is known as ‘harmony’. However, rather than simply adding the signals in equal amounts, we will implement a more general purpose approach.\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T7:**\n",
    "    \n",
    "* Implement a function `mixer()` that adds the original speech with the manipulated speech in different proportions. \n",
    "* Implement a function `harmony()` mixes the input signal with a frequency shifted version of itself (using the funtions `mixer()` and `frequency_shift()`). With your mixer at the 50-50 setting, experiment with different frequency shifts in order to produce the best robotic sounding output. Report \"your optimal\" setting. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mixer(signal1, signal1, percentage_l=0.5):\n",
    "\n",
    "# Your code here to implement mixing of two signals, used later for the harmony effect\n",
    "\n",
    "def mixer(signal1, signal2, percentage_l=0.5):\n",
    "    return(percentage_l*signal1+(1-percentage_l)*signal2)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def harmony(...\n",
    "\n",
    "# Your code here to implement the harmony effect\n",
    "    \n",
    "def harmony(signal1, shift_amount, percentage_l=0.5):\n",
    "    signal2=frequency_shift(signal1, fs,shift_amount)\n",
    "    return(mixer(signal1=signal1,signal2=signal2, percentage_l=percentage_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(harmony(s,350,0.5)/10,rate=fs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to question in Task T7:**\n",
    "\n",
    "<span style=\"font-weight:bold;color:orange\">\n",
    "     <br>\n",
    "My optimal setting as represented above by the audio file is 350,0.5/10  <br>\n",
    "because the sound that is being produced simulates that of a robot without producing a cacophony that would potentially lead to distorted, unrecognisable and unidentifiable sounds.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Frequency Modulation: Vibrato\n",
    "\n",
    "Now that you have the ability to shift the frequencies in a speech signal, it is very easy to implement another common voice manipulation technique - *vibrato*. All that is required is for the frequency shifter to be controlled by the output of an LFO.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T8:**\n",
    "    \n",
    "* Implement a function `vibrato()` by connecting an LFO to your frequency shifter, and experiment with different values for speed and depth . Note that the LFO output will need to be scaled to provide an appropriate frequency shift range and then added to the output of the frequency shift.\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal as sig         # filter designs\n",
    "\n",
    "def lfo(speed_hz, depth, num_samples, fs=44100, square_curve=False):\n",
    "    t = np.linspace(0, num_samples/fs, num = num_samples)\n",
    "    if square_curve==True:\n",
    "        signal1 = depth * sig.square(2 * np.pi * speed_hz * t)\n",
    "    else:\n",
    "        signal1 = depth * np.sin(2*np.pi*speed_hz*t) \n",
    "    return (signal1,t)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://staffwww.dcs.shef.ac.uk/people/S.Goetze/sound/speech.wav -o speech.wav \n",
    "    \n",
    "import soundfile as sf\n",
    "s_file_name = 'speech.wav'\n",
    "s,fs = sf.read(s_file_name)\n",
    "\n",
    "def vibrato(signal,shift_amount,LFO_speed_hz,LFO_square_curve=False,fs=44100):\n",
    "    lfo1,t = lfo(speed_hz=LFO_speed_hz, depth=1, num_samples=1048576, fs=fs, square_curve=LFO_square_curve)\n",
    "    scaled_lfo1 = 0.5 +  0.5*lfo1 #scale signal so it ranges from 0 to shift range\n",
    "    \n",
    "    shift_amount1=shift_amount*scaled_lfo1\n",
    "    return(frequency_shift(signal, fs, shift_amount1))\n",
    "\n",
    "x=vibrato(s,20,LFO_speed_hz=5) \n",
    "ipd.Audio(x/10,rate=fs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Time Delay Effect - Echo and Comb Filter\n",
    "\n",
    "Many interesting voice FX can be achieved by delaying the signal and recombining it with itself. \n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T9:**\n",
    "    \n",
    "* Implement a function `echo()` which mixes a signal $s(t)$ with itself in a delayed version, i.e. $s(t-t_0)$. Experiment with various values for the delay $t_0$, and note the different effects you can achieve with delays \n",
    "  * below $20$ msecs\n",
    "  * between $20$ and $100$ msecs, and \n",
    "  * above $100$ msecs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def echo(...\n",
    "\n",
    "# Your code here to show an example of the echo effect\n",
    "#below 20ms you cant hear the echo since both signals are too close.\n",
    "#at 100ms you hear both sounds clear--echo\n",
    "t=np.linspace(0,len(s)/fs,len(s))\n",
    "\n",
    "def echo(signal, delay):\n",
    "    startsample=int(delay/(1/fs))\n",
    "    print(startsample)\n",
    "    numofsamples=int(len(s));\n",
    "    print(numofsamples)\n",
    "    endsample=numofsamples;\n",
    "    print(endsample)\n",
    "    samplevec=np.linspace(startsample,endsample,numofsamples-startsample);\n",
    "    s1=s[startsample:numofsamples];\n",
    "    s2=s[0:numofsamples-startsample]\n",
    "    xecho=s2+s1;\n",
    "\n",
    "    return(samplevec,xecho);\n",
    "\n",
    "sv,xe=echo(s,0.01)   # below 20 msecs\n",
    "plt.plot(sv,xe)\n",
    "plt.xlabel('$t$');\n",
    "plt.ylabel('$s(t)$');\n",
    "plt.title(\"Time delay effect using echo filter(10 msecs)\")\n",
    "\n",
    "ipd.Audio(xe, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv,xe=echo(s,0.05)   # between 20 and 100 msecs \n",
    "plt.plot(sv,xe)\n",
    "plt.xlabel('$t$');\n",
    "plt.ylabel('$s(t)$');\n",
    "plt.title(\"Time delay effect using echo filter(50 msecs)\")\n",
    "\n",
    "ipd.Audio(xe, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv,xe=echo(s,0.5)  # above 100 msecs\n",
    "plt.plot(sv,xe)\n",
    "plt.xlabel('$t$');\n",
    "plt.ylabel('$s(t)$');\n",
    "plt.title(\"Time delay effect using echo filter(500 msecs)\")\n",
    "\n",
    "ipd.Audio(xe, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Comb Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe that, with delays below $20$ msec in your function `echo()`, the signals combine to create a subtle ‘phasing’ effect. This is known as ‘comb filtering’ as the signal is effectively interfering with itself, and frequency components corresponding to multiples of the delay time are enhanced or cancelled out (due to ‘superposition’). Delays between $20$ and $100$ msecs give the effect of the voice being in a reverberant room. Delays above $100$ msecs sound like distant echoes.\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T10:**\n",
    "    \n",
    "* Visualise the impulse response of your function `echo()` as well as the transfer function. Can you give an explanation from havin a look at the transfer function, why this effect would be called *comb filter*?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impulse response at 100Hz\n",
    "\n",
    "a= signal.unit_impulse(44100,441)\n",
    "print(a.shape)\n",
    "fs3=441000\n",
    "dt3=1/fs3\n",
    "stoptime=0.5\n",
    "ta=np.arange(0,stoptime,dt3)\n",
    "print(ta.shape)\n",
    "#plt.plot(ta,a)\n",
    "plt.plot(a)\n",
    "plt.title(\"Impulse Response\")\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def echo2(signal1, delay):\n",
    "    fs5 = 44100                          # samples per second\n",
    "    startsample=int(delay/(1/fs5))\n",
    "    print(startsample)\n",
    "    numofsamples=int(len(signal1));\n",
    "    print(numofsamples)\n",
    "    endsample=numofsamples;\n",
    "    print(endsample)\n",
    "    samplevec=np.linspace(0,endsample,numofsamples);\n",
    "    s11=np.roll(signal1, startsample)\n",
    "    s21=signal1\n",
    "    xecho=s21+s11;\n",
    "\n",
    "    return(samplevec,xecho);\n",
    "  \n",
    "sv2,xe2=echo2(a,0.01)#value smaller than 20ms\n",
    "plt.plot(sv2,xe2);\n",
    "plt.title(\"Impulse Response with Echo(10msec delay)\")\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('amplitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs5=44100\n",
    "FFT_length = 2**15\n",
    "freq5= np.linspace(0, fs5/2, num=int((FFT_length/2)+1))#we only plot half of the fft lenght (the positive half)--the other half is in the negative axis and mirrored \n",
    "spectrum2= np.abs(np.fft.rfft(xe2,FFT_length))\n",
    "print(spectrum2.shape)\n",
    "print(freq5.shape)\n",
    "\n",
    "plt.plot(freq5[0:2000],spectrum2[0:2000])\n",
    "plt.title(\"Spectrum for Echo function(comb effect)\")\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('amplitude')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to question in Task T10:**\n",
    "\n",
    "<span style=\"font-weight:bold;color:orange\">\n",
    "    After using a small frequency and zoom in to that frequency, it's noticable that the frequencies have the shape of a comb. That is evident from the plot above.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Flanger \n",
    "\n",
    "It is possible to use an LFO to vary the delay. The resulting effect is known as a *flanger*.\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T11:**\n",
    "    \n",
    "* Add an LFO to your ‘delay’ to create a ‘flanger’, and experiment with different settings. Note that you will need to scale the output of the LFO, and you will get different effects depending on whether the delayed signal is mixed with the original or not.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Frequency Analysis\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #9696ff;\">\n",
    "    \n",
    "**Question Q5:**\n",
    "\n",
    "* COM3502-4502-6502: \n",
    "    * What does FFT stand for and what does an FFT do?\n",
    "* COM4502-6502 ONLY: What is a DFT and how is it different from an FFT?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Question Q5:**\n",
    "\n",
    "<span style=\"font-weight:bold;color:orange\">\n",
    "    First question: FFT is an abbreviation of Fast Fourier transform. More specifically, it is a mathematical algorithm used in signal processing that makes conversions made by DFT (abbreviation for Discrete Fourier Transform) faster and more efficient by reducing the number of computations needed.\n",
    "    Second question: DFT is also a mathematical algorithm that contributes in processing digital signals by calculating the spectrum of a finite-duration signal. DFT works by transforming N discrete-time domain samples of signals to the frequency domain components. In some applications, the shape of the time domain is not applicable for signals. In occasions like these signal frequency content becomes very useful. \n",
    "    FFT is an implementation of DFT whilst DFT illustrates a relationship between the time domain and the frequency domain representation.\n",
    "    DFT is a mathematical algorithm that converts time-domain signals to frequency domain components, while in contrast, FFT algorithm involves several computation techniques including DFT.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Spectrogram Step-by-Step (for COM4502-6502 only)\n",
    "\n",
    "The magnitude $|X[n, \\ell]|$ of the STFT for all $n$ and $\\ell$ is known as the [spectrogram](https://en.wikipedia.org/wiki/Spectrogram) of a signal. It is frequently used to analyze signals in the time-frequency domain, for instance by a [spectrum analyzer](https://en.wikipedia.org/wiki/Spectrum_analyzer). It can be interpreted as a *image* of the signal with (block) time direction on the $x$ axis and (discrete) frequency $n$ on the y axis.\n",
    "\n",
    "From Lab Sheet 3 we already know how to brack a long signal into block, a.k.a. frames.\n",
    "\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task 12: Manual Spectrogram Calculation (for COM4502-6502 only)**\n",
    "    \n",
    "<ul>\n",
    "    <li> \n",
    "        Implement a function <code>calc_SpectralPoint(xk,n)</code> which calculates a spectral point for one discrete frequency $n$ from a input frame $x[k]$, i.e. a function which implements the well-known DFT equation\n",
    "    $$\n",
    "    \\mathrm{DFT}\\{x[k]\\}   =  X[n] = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}\n",
    "    $$ \n",
    "    for one fixed $n$.\n",
    "    </li>\n",
    "    <li> \n",
    "        Implement a very similar function <code>calc_SpectralPointWindowed(xk,n)</code> which calculates a spectral point for one discrete frequency $n$ from a input frame $x[k]$, but in addition applies a window function $w[k]$ to the frame $x[k]$, i.e. the function should calculate\n",
    "    $$\n",
    "    \\mathrm{DFT}\\{w[k] \\cdot x[k]\\}   =  X^{\\mathrm{w}}[n] = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} w[k] x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}\n",
    "    $$ \n",
    "    for one fixed $n$. The window should have the same length $L_{\\mathrm{DFT}}$ as your frame and should be one of the windows we discussed during the lecture.\n",
    "    </li>\n",
    "    <li> \n",
    "        The functions above only calculates one spectral value at a time. To obtain a full spectrum , implement a function <code>calc_Manitude_Spectrum()</code> which transforms every windowed frame to the frequency domain and calculates all positive frequencies, i.e. for $0 \\leq n \\leq L_{\\mathrm{DFT}}/2+1$.\n",
    "    </li>\n",
    "    <li> \n",
    "        Create a function <code>create_spectrogram()</code>, which splits the complete input sequence (e.g. a loaded WAVE file) into blocks of length $L_{\\mathrm{DFT}}$. These may be overlapping. For each block the spectrum should be calculated using the previously implemented function <code>calc_Manitude_Spectrum()</code> and all spectra should be collected to form a spectrogram (e.g. as columns of a matrix).\n",
    "    </li>\n",
    "    <li> \n",
    "        Concatenate the resulting spectra to a spectrogram and display the resulting spectrogram. You can use <code>matplotlib</code>'s <code><a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html\">imshow()</a></code> function for manually plotting the spectrogram image. Note that a spectrogram is usally shown in dB scaling.\n",
    "    </li>\n",
    "    <li>\n",
    "        Visulalise the input signal $x[k]$ as spectrogram for (i) a speech signal and (ii) for a chirp/sweep signal. \n",
    "    </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the  DFT equation\n",
    "    $$\\mathrm{DFT}\\{x[k]\\}   =  X[n] = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}$$ for one fixed $n$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate spectral point for discrete frequency 'n'\n",
    "def calc_SpectralPoint(xk,n):\n",
    "    sum=0\n",
    "    for k in range(len(xk)):\n",
    "        sum =sum+ xk[k]*np.exp(2j*np.pi*k*n/len(xk))\n",
    "    Xn=sum/len(xk)\n",
    "    return(Xn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement DFT of windowed frame\n",
    "$$\\mathrm{DFT}\\{w[k] \\cdot x[k]\\}   =  X^{\\mathrm{w}}[n]  = \\frac{1}{L_{\\mathrm{DFT}}} \\sum \\limits_{k=0}^{L_{\\mathrm{DFT}}-1} w[k] x[k]  e^{j 2 \\pi k n /L_{\\mathrm{DFT}}}$$ for one fixed $n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_SpectralPointWindowed(xk,n,window=False):\n",
    "    sum=0\n",
    "    win = np.ones(len(xk))\n",
    "    a=np.empty(len(xk))\n",
    "    if window==True:\n",
    "        for i in range(len(xk)):\n",
    "            win[i]=0.5*(1-np.cos(2*np.pi*i/len(xk)))\n",
    "    for d in range(len(xk)):\n",
    "        sum = sum + win[d]*xk[d]*np.exp((2j*np.pi*d*n)/len(xk))\n",
    "    Xwn=sum/len(xk)\n",
    "    return(Xwn)\n",
    "calc_SpectralPointWindowed(s,200,window=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function <code>calc_Manitude_Spectrum()</code> is supposed to transform every (windowed or not windowed) frame to the frequency domain and to calculate all positive frequencies, i.e. $X[n]$ or $X^{\\mathrm{w}}[n]$ for $0 \\leq n \\leq L_{\\mathrm{DFT}}/2+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function <code>create_spectrogram()</code> should calculate all spectra needed for your spectrogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Manitude_Spectrum(xk):\n",
    "    FFT_length = 2**15 # take a power of two which is larger than the signal length\n",
    "    f = np.linspace(0, fs/2, num=int(FFT_length/2+1))\n",
    "    spectrum = np.abs(np.fft.rfft(xk,n=FFT_length))\n",
    "    # plot the spectrum\n",
    "    plt.plot(f,spectrum)\n",
    "    plt.title('Visualisation of the signal in spectal domain')\n",
    "    plt.xlabel('frequency $f$ in Hz')\n",
    "    plt.ylabel('$x(f)$')\n",
    "    return(spectrum)\n",
    "\n",
    "calc_Manitude_Spectrum(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(x, L_DFT=512, noverlap):\n",
    "    '''\n",
    "           x: original time series\n",
    "       L_DFT: The number of data points used in each block for the DFT. The default value is 512. \n",
    "    noverlap: The number of points of overlap between blocks. The default value is 256. \n",
    "    '''\n",
    "    # Your code here\n",
    "    # ...    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can be used to actually display the created spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram( #..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code actually calculates and plots your spectrogram (for the two signals mentioned above). Feel free to adapt parameters `L_DFT` and `noverlap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load or create signal\n",
    "\n",
    "# create and plot spectrogram (generated using your functions above)\n",
    "L_DFT    = 256 # DFT length\n",
    "noverlap = 84  # number of overlapping samples\n",
    "starts, spec = create_spectrogram( #...\n",
    "plot_spectrogram(#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Equaliser (for COM4502-6502 only)\n",
    "\n",
    "We want to design an equaliser like shown in the picture below as a hardware system.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Yamaha_EQ-500_Graphic_Equalizer.jpg/1920px-Yamaha_EQ-500_Graphic_Equalizer.jpg\" align=\"center\" style=\"width: 500px;\"/>\n",
    "<center><span style=\"font-size:smaller\">\n",
    "    Picture taken from <a href=\"https://simple.wikipedia.org/wiki/Equalization_(audio)\">Wikipedia</a>, license: <a href=\"https://creativecommons.org/licenses/by/2.0/\">CC BY 2.0</a>\n",
    "</span></center>\n",
    "\n",
    "\n",
    "The following function realises one of the sliders in software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaking_filter(gain,center_freq,q,fs):\n",
    "    \"\"\"\n",
    "    Derive coefficients for a peaking filter with a given amplitude and\n",
    "     bandwidth.  All coefficients are calculated as described in Zolzer's\n",
    "     DAFX book (p. 50 - 55).  This algorithm assumes a constant q-term\n",
    "     is used through the equation.\n",
    "    \n",
    "    Usage:     `b,a` = peaking_filter(gain,center_freq, q,fs)\n",
    "                `gain` is the logrithmic gain (in dB)\n",
    "                `center_freq` is the center frequency\n",
    "                `q` is q-term equating to (Fb / Fc)\n",
    "                `fs` is the sampling rate\n",
    "    \n",
    "    Author:    Jeff Tackett 08/22/05\n",
    "    Port to Python by George Close 10/07/21\n",
    "    \"\"\"\n",
    "    \n",
    "    gain = np.float32(gain)\n",
    "    k = np.tan((np.pi*center_freq)/fs)\n",
    "    V0 = 10**((gain)/20)\n",
    "    # invert gain if a cut\n",
    "    if V0 < 1:\n",
    "        V0 = 1/V0\n",
    "\n",
    "    # Boost\n",
    "    if gain > 0:\n",
    "        b0 = (1 + ((V0/q)*k)+ k**2) / (1+((1/q)*k)+k**2)\n",
    "        b1 = (2 * (k**2 - 1)) / (1 + ((1/q)*k) + k**2);\n",
    "        b2 = (1 - ((V0/q)*k) + k**2) / (1 + ((1/q)*k) + k**2);\n",
    "        a1 = b1;\n",
    "        a2 =  (1 - ((1/q)*k) + k**2) / (1 + ((1/q)*k) + k**2);\n",
    "    # Cut\n",
    "    elif gain <0:\n",
    "        b0 = (1 + ((1/q)*k) + k**2) / (1 + ((V0/q)*k) + k**2);\n",
    "        b1 =       (2 * (k**2 - 1)) / (1 + ((V0/q)*k) + k**2);\n",
    "        b2 = (1 - ((1/q)*k) + k**2) / (1 + ((V0/q)*k) + k**2);\n",
    "        a1 = b1;\n",
    "        a2 = (1 - ((V0/q)*k) + k**2) / (1 + ((V0/q)*k) + k**2);\n",
    "    #gain is 0\n",
    "    else:\n",
    "        b0 = V0;\n",
    "        b1 = 0;\n",
    "        b2 = 0;\n",
    "        a1 = 0;\n",
    "        a2 = 0;\n",
    "    a = [  1, a1, a2];\n",
    "    b = [ b0, b1, b2];\n",
    "    return b,a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T13: (for COM4502-6502 only)**\n",
    "    \n",
    "* Visualise the frequency response of one filter.\n",
    "* Implement a cascade of filters to realise an equaliser.\n",
    "* Visualise the frequency response of your equaliser filter and the input and (filtered) output signal.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using gain = 5, center frequency = 5000, q-factor = 2, sampling frequncy = 44100\n",
    "b,a = peaking_filter(gain= 5,center_freq= 5000, q = 2,fs= 44100)\n",
    "print(a,b)\n",
    "f_eq,h_eq = signal.freqz(b,a)\n",
    "omega_eq = np.linspace(0,1,len(f_eq))\n",
    "# plot filter\n",
    "plt.plot(omega_eq,np.abs(h_eq), lw=2, label='Equaliser')\n",
    "plt.title(\"Frequency response of peaking filter\")\n",
    "plt.xlabel('f/fs')\n",
    "plt.ylabel('Gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascade filter\n",
    "b1,a1 = peaking_filter(gain= 5,center_freq= 50, q = 2,fs= 44100)\n",
    "b2,a2 = peaking_filter(gain= 5,center_freq= 500, q = 2,fs= 44100)\n",
    "b3,a3 = peaking_filter(gain= 5,center_freq= 300, q = 2,fs= 44100)\n",
    "\n",
    "f_eq1,h_eq1 = signal.freqz(b1,a1)\n",
    "f_eq2,h_eq2 = signal.freqz(b2,a2)\n",
    "f_eq3,h_eq3 = signal.freqz(b3,a3)\n",
    "h_eq4 = h_eq1 + h_eq2 + h_eq3-3\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(omega_eq[0:100],np.abs(h_eq4[0:100]), lw=4, label='Equaliser')\n",
    "plt.title(\"Cascade filters\")\n",
    "plt.xlabel('f/fs')\n",
    "plt.ylabel('Gain') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_filtered11 = signal.filtfilt(b1, a1, s) \n",
    "s_filtered22 = signal.filtfilt(b2, a2, s_filtered11) \n",
    "s_filtered33 = signal.filtfilt(b3, a3, s_filtered22) \n",
    "\n",
    "plt.plot(t,s_filtered33)\n",
    "plt.title(\"Cascade filters\")\n",
    "plt.xlabel('f/fs')\n",
    "plt.ylabel('Gain') \n",
    "\n",
    "ipd.Audio(s_filtered33/10,rate=fs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare for submission\n",
    "\n",
    "<br>\n",
    "<div style=\"border: 2px solid #999; padding: 10px; background: #abe;\">\n",
    "    \n",
    "**Task T14:**\n",
    " \n",
    "* Clear all cell outputs to reduce the file size (in Jupyter Notebooks clivk on \"Cell->All Output->Clear\")\n",
    "* Create a `.zip` file named `YourName.zip` containing this Jupyter Notebook files as well as all other file necessary to run this notebook (**if such exist**, e.g. if you created (additional) WAVE files). \n",
    "* Hand-in your `.zip` file via Blackboard.\n",
    "    \n",
    "\n",
    "<span style=\"font-weight:bold;color:red;text-align:center;\">**Important: For marking, we expect your code to work ‘out of the box’.**</span> This means that no additional software should have to be installed to make the Notebook run. If you only used libraries known from the Speech Processing Lab classes, you should be safe here.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SP_final_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
